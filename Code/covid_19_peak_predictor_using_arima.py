# -*- coding: utf-8 -*-
"""Covid-19-Peak-Predictor-using-ARIMA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nGqA4jC2qZIVa3bHz-ebxskucwoUUocn

# Covid-19-Peak-Predictor-using-ARIMA-LSTM-and-FBProphet
1. Data Source from OUR WORLD in Data GitHub repository.
2. Goal to predict COVID-19 peak using Time Series Analysis
3. Dataset available here: https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data.csv
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import scipy
from matplotlib import dates
from fbprophet import Prophet
import pandas as pd
import matplotlib.pyplot as plt 
import numpy as np
from IPython.display import Javascript
from datetime import datetime
from pandas.api.types import is_numeric_dtype
from google.colab import files
import os
import time
import getpass
import statistics
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.pylab import rcParams
import statsmodels.api as sm
from pylab import rcParams
import missingno as msno
!pip install geopandas #for map
import geopandas as gpd
from pandas import DataFrame
from pandas import to_datetime

import seaborn as sns
sns.set_style('whitegrid')
pd.set_option('display.max_rows', 55)

#import sklearn packages
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler, MinMaxScaler

#import statsmodels
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller #Dickey-Fuller Test
from statsmodels.tsa.seasonal import seasonal_decompose 
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tools.eval_measures import rmse
from statsmodels.tsa.holtwinters import Holt

#Import ARIMA packages
!pip install pmdarima
import pmdarima as pm
from pmdarima.model_selection import train_test_split
from pmdarima.arima import ADFTest

# Use bokeh to plot predictions
import bokeh.io
bokeh.io.reset_output()
bokeh.io.output_notebook()
from bokeh.plotting import figure, show, output_notebook
from bokeh.io import output_notebook
from bokeh.models import Legend
from bokeh.models import NumeralTickFormatter

#loading the URL
covid_url = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv'
#read the CSV file
cdata = pd.read_csv(covid_url, error_bad_lines=False)

#Number of columns
cdata.head()

#Display all rows
pd.set_option('display.max_rows',None)

#Total rows
cdata.shape

#Checking for null values
cdata.isnull().sum()

#Dropping unrequired columns
cdata.drop(['excess_mortality_cumulative_per_million','excess_mortality_cumulative_absolute','excess_mortality_cumulative','excess_mortality','human_development_index','hospital_beds_per_thousand','handwashing_facilities','male_smokers','female_smokers','gdp_per_capita','diabetes_prevalence','cardiovasc_death_rate','extreme_poverty','gdp_per_capita','population_density','reproduction_rate','continent'],axis=1, inplace= True)

cdata.head()

#Checking columns with 80% null values 
cdata.isnull().sum() >= (119656 * 0.80)

# dropping column with 80% null values
cdata.drop(['icu_patients','icu_patients_per_million','hosp_patients','hosp_patients_per_million','weekly_hosp_admissions','weekly_hosp_admissions_per_million','weekly_icu_admissions','weekly_icu_admissions_per_million'],axis=1,inplace= True)

cdata.head(1)

plt.subplots(figsize=(20,15))
sns.heatmap(cdata.isnull(), cbar=False)

#Fill NaN values with 0
cdata.fillna(0,inplace=True)

cdata.isnull().sum()

cdata.head(10)

plt.subplots(figsize=(20,15))
sns.heatmap(cdata.isnull(), cbar=False)

cdata['location'].unique()

"""# ARIMA Forecast"""

# Checking for stationary values
nation = 'Norway'
ndata = cdata
ndata.head(2)
ndata['Date'] = pd.to_datetime(ndata['date'])
df2 = ndata.copy()
df2.set_index('Date', inplace= True)
ndata2 = df2[df2['location'].isin([nation])]
ndata2.head(2)
ndata2.dropna(inplace= True)
ndata2.drop(['new_people_vaccinated_smoothed_per_hundred','new_people_vaccinated_smoothed','iso_code','location','date','total_cases','new_cases','new_cases_smoothed','total_deaths','new_deaths','new_deaths_smoothed','total_cases_per_million','new_cases_smoothed_per_million','total_deaths_per_million','new_deaths_per_million','new_deaths_smoothed_per_million','new_tests','total_tests','total_tests_per_thousand','new_tests_per_thousand','new_tests_smoothed','new_tests_smoothed_per_thousand','positive_rate','tests_per_case','tests_units','total_vaccinations','people_vaccinated','people_fully_vaccinated','total_boosters','new_vaccinations','new_vaccinations_smoothed','total_vaccinations_per_hundred','people_vaccinated_per_hundred','people_fully_vaccinated_per_hundred','total_boosters_per_hundred','new_vaccinations_smoothed_per_million','stringency_index','population','median_age','aged_65_older','aged_70_older','life_expectancy'],axis=1,inplace= True)
sns.heatmap(ndata2.isnull(), cbar=False)

ndata2 = ndata2.fillna(method='ffill')

ndata2.head(4)

ndata2.plot()

import statsmodels.api as sm

decomposition = sm.tsa.seasonal_decompose(ndata2['new_cases_per_million'], model='additive', extrapolate_trend='freq') #additive or multiplicative is data specific
fig = decomposition.plot()
plt.rcParams["figure.figsize"] = (20, 10)
plt.show()

def adfuller_test(sales):
    result=adfuller(sales)
    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations']
    for value,label in zip(result,labels):
        print(label+' : '+str(value) )

    if result[1] <= 0.05:
      print("strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary")
    else:
      print("weak evidence against null hypothesis,indicating it is non-stationary ")

adfuller_test(ndata2['new_cases_per_million'])

from matplotlib import pyplot
from pandas.plotting import autocorrelation_plot

autocorrelation_plot(ndata2['new_cases_per_million'])
pyplot.show()

import itertools
p = d = q = range(0, 2)

#generate patterns from p,q,r
pdq = list(itertools.product(p, d, q))

seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]

print('Examples of parameter combinations for SARIMA..')
print('SARIMAX: {} * {}'.format(pdq[1], seasonal_pdq[1]))
print('SARIMAX: {} * {}'.format(pdq[1], seasonal_pdq[1]))
print('SARIMAX: {} * {}'.format(pdq[2], seasonal_pdq[2]))
print('SARIMAX: {} * {}'.format(pdq[3], seasonal_pdq[2]))

import warnings
import statsmodels.api as sm

aic=[]
d=1

warnings.filterwarnings("ignore")
for param in pdq:
    for param_seasonal in seasonal_pdq:
        try:
            mod = sm.tsa.statespace.SARIMAX(
                ndata2.new_cases_per_million[:'2021-04-01'],
                order=param, seasonal_order=param_seasonal,
                enforce_stationarity=False,
                enforce_invertibility=False)
            results = mod.fit(disp=0)
            aic.append(results.aic)
            print('SARIMA{}*{}12 - AIC:{}'.format(param, param_seasonal, results.aic))
        except:
            continue

print(min(aic))

mod = sm.tsa.statespace.SARIMAX(ndata2.new_cases_per_million,
                                order=(1, 1, 1),
                                seasonal_order=(0, 1, 1, 12),
                                trend='t')

results = mod.fit()

print(results.summary().tables[1])

ndata2['new_cases_per_million'].head()

pred = results.get_prediction(start=pd.to_datetime('2021-04-01'), dynamic=False, full_results=True)
pred_ci = pred.conf_int()

ax = ndata2.new_cases_per_million['2020':].plot(label='observed',figsize=(30, 10))
pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7)

ax.fill_between(pred_ci.index,
                pred_ci.iloc[:, 0],
                pred_ci.iloc[:, 1], color='k', alpha=.2)

ax.set_xlabel('Date')
ax.set_ylabel('new_cases_per_million')
plt.legend()
plt.title('Predicitng actual data vs Real data for '+ nation, fontsize=30)
plt.show()

from numpy import sqrt 
from sklearn.metrics import mean_squared_error

y_forecasted = pred.predicted_mean
y_truth = ndata2.new_cases_per_million['2021-04-01':]

rmse = sqrt(mean_squared_error(y_truth, y_forecasted).mean())
print('The RMSE error of forecast prediction is {}'.format(round(rmse, 2)))

y_forecasted = pred.predicted_mean
y_truth = ndata2.new_cases_per_million

# Compute the mean square error
mse = ((y_forecasted - y_truth) ** 2).mean()
print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))

pred_uc = results.get_forecast(steps=60)

# Get confidence intervals of forecasts
pred_ci = pred_uc.conf_int()

ax = ndata2.plot(label='observed', figsize=(30, 10))
pred_uc.predicted_mean.plot(ax=ax, label='Forecast')
ax.fill_between(pred_ci.index,
                pred_ci.iloc[:, 0],
                pred_ci.iloc[:, 1], color='k', alpha=.25)
ax.set_xlabel('Date')
ax.set_ylabel('new_cases_per_million')
plt.title('Future COVID-19 wave in  '+ nation, fontsize=30)
plt.legend()
plt.show()

data2 = ndata2.new_cases_per_million[:'2021-04-01']

smodel = pm.auto_arima(data2, start_p=1, start_q=1,
                         test='adf',
                         max_p=3, max_q=3, m=7,
                         start_P=0, seasonal=True,
                         d=None, D=1, trace=True,
                         error_action='ignore',  
                         suppress_warnings=True, 
                         stepwise=True)

smodel.summary()

data= ndata2.new_cases_per_million[:'2021-04-01']
data.head()

# Predicitng actual data vs Real data

n_periods = 10
fitted, confint = smodel.predict(n_periods=n_periods, return_conf_int=True)
index_of_fc = pd.date_range(data.index[-1], periods = n_periods, freq='W')

# make series for plotting purpose
fitted_series = pd.Series(fitted, index=index_of_fc)
lower_series = pd.Series(confint[:, 0], index=index_of_fc)
upper_series = pd.Series(confint[:, 1], index=index_of_fc)

# Plot
plt.plot(data)
plt.plot(ndata2.new_cases_per_million[:'2021-08-01'],color='blue')
plt.plot(fitted_series, color='darkgreen')
plt.fill_between(lower_series.index, 
                 lower_series, 
                 upper_series, 
                 color='k', alpha=.1)

plt.title('Predicitng actual data vs Real data for '+ nation, fontsize=30)
plt.show()

# ARIMA FOrecasting Future 

fdata = ndata2
smodel = pm.auto_arima(fdata, start_p=1, start_q=1,
                         test='adf',
                         max_p=3, max_q=3, m=7,
                         start_P=0, seasonal=True,
                         d=None, D=1, trace=True,
                         error_action='ignore',  
                         suppress_warnings=True, 
                         stepwise=True)

smodel.summary()

n_periods = 10
fitted, confint = smodel.predict(n_periods=n_periods, return_conf_int=True)
index_of_fc = pd.date_range(fdata.index[-1], periods = n_periods, freq='W')

# make series for plotting purpose
fitted_series = pd.Series(fitted, index=index_of_fc)
lower_series = pd.Series(confint[:, 0], index=index_of_fc)
upper_series = pd.Series(confint[:, 1], index=index_of_fc)

# Plot
plt.plot(fdata)
plt.plot(ndata2.new_cases_per_million,color='blue')
plt.plot(fitted_series, color='Orange')
plt.fill_between(lower_series.index, 
                 lower_series, 
                 upper_series, 
                 color='k', alpha=.1)

plt.title('Upcoming COVID-19 wave in '+ nation, fontsize=30)
plt.show()

from numpy import sqrt 
from sklearn.metrics import mean_squared_error

